{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 5 Submission to Kaggle - Digit Recognizer \n",
    "\n",
    "Due Sunday by 11:59pm Points 10 Submitting a text entry box or a file upload \n",
    "\n",
    "1. go to [kaggle](https://www.kaggle.com/c/digit-recognizer/data)\n",
    "2. Build a model using the training data using any technique you like  \n",
    "2.1. read train, test data into data frames and normalize  \n",
    "2.2. build a model via a keras neural network and train it\n",
    "3. Follow the directions to make a submission.  \n",
    "3.1. use the model to predict results  \n",
    "3.2. submit results to kaggle and get screen shot\n",
    "4. Take a screenshot or snip of your result on the leaderboard\n",
    "5. ensemble with other methods  \n",
    "5.1 MLP, RandomForest, SVC classifier  \n",
    "5.2 ensemble with voting  \n",
    "6. Follow the directions to make a submission.  \n",
    "6.1. use the model to predict results  \n",
    "6.2. submit results to kaggle and get screen shot\n",
    "7. Take a screenshot or snip of your result on the leaderboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disable autoscrolling of output per [SO:answer](https://stackoverflow.com/a/41646557)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
       "    return false;\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fully show all cell output per [SO:answer](https://stackoverflow.com/a/36835741)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AFMS\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.10.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'3.6.6 |Anaconda custom (64-bit)| (default, Jun 28 2018, 11:27:44) [MSC v.1900 64 bit (AMD64)]'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/c/Users/AFMS/r/rn/rw/dm2/hw/05/out\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import tensorflow as tf # pip install tensorflow_gpu\n",
    "from keras import backend as K # pip install keras\n",
    "import keras.callbacks\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import sys\n",
    "tf.__version__\n",
    "sys.version\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. go to kaggle\n",
    "\n",
    "Downloaded train.csv and test.csv datasets to ../in folder from [kaggle.com/c/digit-recognizer/data](https://www.kaggle.com/c/digit-recognizer/data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../in/sample_submission.csv\n",
      "../in/test.csv\n",
      "../in/train.csv\n"
     ]
    }
   ],
   "source": [
    "!ls ../in/*.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build a model using the training data using any technique you like\n",
    "\n",
    "### 2.1. read train, test data into data frames and normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Has any Nan: False\n",
      "y:(42000,) int64; X:(42000, 784)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    0\n",
       "2    1\n",
       "Name: label, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "count    42000.000000\n",
       "mean         4.456643\n",
       "std          2.887730\n",
       "min          0.000000\n",
       "25%          2.000000\n",
       "50%          4.000000\n",
       "75%          7.000000\n",
       "max          9.000000\n",
       "Name: label, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 255\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pixel0      int64\n",
       "pixel1      int64\n",
       "pixel2      int64\n",
       "pixel3      int64\n",
       "pixel4      int64\n",
       "pixel5      int64\n",
       "pixel6      int64\n",
       "pixel7      int64\n",
       "pixel8      int64\n",
       "pixel9      int64\n",
       "pixel10     int64\n",
       "pixel11     int64\n",
       "pixel12     int64\n",
       "pixel13     int64\n",
       "pixel14     int64\n",
       "pixel15     int64\n",
       "pixel16     int64\n",
       "pixel17     int64\n",
       "pixel18     int64\n",
       "pixel19     int64\n",
       "pixel20     int64\n",
       "pixel21     int64\n",
       "pixel22     int64\n",
       "pixel23     int64\n",
       "pixel24     int64\n",
       "pixel25     int64\n",
       "pixel26     int64\n",
       "pixel27     int64\n",
       "pixel28     int64\n",
       "pixel29     int64\n",
       "            ...  \n",
       "pixel754    int64\n",
       "pixel755    int64\n",
       "pixel756    int64\n",
       "pixel757    int64\n",
       "pixel758    int64\n",
       "pixel759    int64\n",
       "pixel760    int64\n",
       "pixel761    int64\n",
       "pixel762    int64\n",
       "pixel763    int64\n",
       "pixel764    int64\n",
       "pixel765    int64\n",
       "pixel766    int64\n",
       "pixel767    int64\n",
       "pixel768    int64\n",
       "pixel769    int64\n",
       "pixel770    int64\n",
       "pixel771    int64\n",
       "pixel772    int64\n",
       "pixel773    int64\n",
       "pixel774    int64\n",
       "pixel775    int64\n",
       "pixel776    int64\n",
       "pixel777    int64\n",
       "pixel778    int64\n",
       "pixel779    int64\n",
       "pixel780    int64\n",
       "pixel781    int64\n",
       "pixel782    int64\n",
       "pixel783    int64\n",
       "Length: 784, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "\n",
       "[3 rows x 784 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def load_yX(filename, sep=','):\n",
    "    df = pd.read_csv(filename, sep=sep)\n",
    "    y = df.iloc[:,0]\n",
    "    X = df.iloc[:,1:]\n",
    "    return y, X\n",
    "\n",
    "def peekprint_yX(y, X, head_count=3):\n",
    "    print(\"Has any Nan: {}\".format(y.isnull().values.any() or X.isnull().values.any()))\n",
    "    print(\"y:{} {}; X:{}\".format(y.shape, y.dtypes, X.shape))\n",
    "    display(y.head(head_count))\n",
    "    display(y.describe())\n",
    "    print(X.min().min(), X.max().max())\n",
    "    display(X.dtypes)\n",
    "    display(X.head(head_count))\n",
    "\n",
    "def show_row(df, ndx):\n",
    "    plt.imshow(df.iloc[ndx].values.reshape(28,28), cmap=plt.cm.binary)\n",
    "\n",
    "y_train, x_train = load_yX('../in/train.csv')\n",
    "peekprint_yX(y_train, x_train)\n",
    "show_row(x_train, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 1]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1_train = np_utils.to_categorical(y_train).astype(int)\n",
    "y1_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Has any Nan: False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(28000, 784)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 255\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pixel0      int64\n",
       "pixel1      int64\n",
       "pixel2      int64\n",
       "pixel3      int64\n",
       "pixel4      int64\n",
       "pixel5      int64\n",
       "pixel6      int64\n",
       "pixel7      int64\n",
       "pixel8      int64\n",
       "pixel9      int64\n",
       "pixel10     int64\n",
       "pixel11     int64\n",
       "pixel12     int64\n",
       "pixel13     int64\n",
       "pixel14     int64\n",
       "pixel15     int64\n",
       "pixel16     int64\n",
       "pixel17     int64\n",
       "pixel18     int64\n",
       "pixel19     int64\n",
       "pixel20     int64\n",
       "pixel21     int64\n",
       "pixel22     int64\n",
       "pixel23     int64\n",
       "pixel24     int64\n",
       "pixel25     int64\n",
       "pixel26     int64\n",
       "pixel27     int64\n",
       "pixel28     int64\n",
       "pixel29     int64\n",
       "            ...  \n",
       "pixel754    int64\n",
       "pixel755    int64\n",
       "pixel756    int64\n",
       "pixel757    int64\n",
       "pixel758    int64\n",
       "pixel759    int64\n",
       "pixel760    int64\n",
       "pixel761    int64\n",
       "pixel762    int64\n",
       "pixel763    int64\n",
       "pixel764    int64\n",
       "pixel765    int64\n",
       "pixel766    int64\n",
       "pixel767    int64\n",
       "pixel768    int64\n",
       "pixel769    int64\n",
       "pixel770    int64\n",
       "pixel771    int64\n",
       "pixel772    int64\n",
       "pixel773    int64\n",
       "pixel774    int64\n",
       "pixel775    int64\n",
       "pixel776    int64\n",
       "pixel777    int64\n",
       "pixel778    int64\n",
       "pixel779    int64\n",
       "pixel780    int64\n",
       "pixel781    int64\n",
       "pixel782    int64\n",
       "pixel783    int64\n",
       "Length: 784, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "\n",
       "[3 rows x 784 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def load_X(filename, sep=','):\n",
    "    df = pd.read_csv(filename, sep=sep)\n",
    "    return df\n",
    "\n",
    "def peekprint_X(X, head_count=3):\n",
    "    print(\"Has any Nan: {}\".format(X.isnull().values.any()))\n",
    "    display(X.shape)\n",
    "    print(X.min().min(), X.max().max())\n",
    "    display(X.dtypes)\n",
    "    display(X.head(head_count))\n",
    "\n",
    "x_test = load_X('../in/test.csv')\n",
    "peekprint_X(x_test)\n",
    "show_row(x_test,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize on train data and apply to test data.  Note training set min 0 and max 255 from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 1.0\n",
      "0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "xn_train = x_train.applymap(lambda v: v/255.0)\n",
    "xn_test = x_test.applymap(lambda v: v/255.0)\n",
    "print(xn_train.min().min(), xn_train.max().max())\n",
    "print(xn_test.min().min(), xn_test.max().max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. build a model via a keras neural network and train it\n",
    "\n",
    "set keras random seed to deliver same results each time per [SO:a](https://stackoverflow.com/a/52897216)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_seed(v):\n",
    "    os.environ['PYTHONHASSEED']=str(v)\n",
    "    random.seed(v)\n",
    "    np.random.seed(v)\n",
    "    tf.set_random_seed(v)\n",
    "\n",
    "set_random_seed(7)\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set keras to stop when loss is minimal or no longer improving  \n",
    "\n",
    "[keras docs](https://keras.io/callbacks/#earlystopping)\n",
    "```\n",
    "keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto', baseline=None, restore_best_weights=False)\n",
    "\n",
    "keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "```\n",
    "\n",
    "[so:a](https://stackoverflow.com/a/37296168/1134881)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStoppingByLossVal(keras.callbacks.Callback):\n",
    "    def __init__(self, monitor='loss', value=0.00001, verbose=0):\n",
    "        super(keras.callbacks.Callback, self).__init__()\n",
    "        self.monitor = monitor\n",
    "        self.value = value\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        current = logs.get(self.monitor)\n",
    "        if current is None:\n",
    "            warnings.warn(\"Early stopping requires {} available!\".format(self.monitor))\n",
    "        elif current < self.value:\n",
    "            if self.verbose > 0:\n",
    "                print(\"Epoch {}: early stopping fit\".format(epoch))\n",
    "            self.model.stop_training = True\n",
    "            \n",
    "callbacks = [\n",
    "    EarlyStoppingByLossVal(monitor='loss', value=0.0001, verbose=1),\n",
    "    #keras.callbacks.EarlyStopping(monitor='loss', patience=6, min_delta=0.000005, verbose=1),\n",
    "    keras.callbacks.ModelCheckpoint(filepath='./weights/weights.hdf5', monitor='val_loss', save_best_only=True, verbose=0)]   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.models.Sequential()\n",
    "# model.add(tf.keras.layers.Flatten())\n",
    "# model.add(tf.keras.layers.Dense(784, activation=tf.nn.relu))\n",
    "# model.add(tf.keras.layers.Dropout(0.2))\n",
    "# model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
    "# model.add(tf.keras.layers.Dropout(0.2))\n",
    "# model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))\n",
    "# model.compile(optimizer='adam',\n",
    "#              loss='sparse_categorical_crossentropy',\n",
    "#              metrics=['accuracy'])\n",
    "# model.fit(xn_train.values.reshape(42000,28,28), y_train.values, batch_size=420, epochs=30, callbacks=callbacks)\n",
    "# model.save('kdigit.model')\n",
    "# m = tf.keras.models.load_model('kdigit.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above  model obtained and accuracy of 0.98257 on test data with basic NN above (non-CNN).\n",
    "\n",
    "Add a CNN layer in the begining and see if we can get better results.\n",
    "\n",
    "Must reshape the data from each image being in 784 flattened pixels to being (28,28) pixels.\n",
    "Keras Conv2D layer also looks like it is expects the last dimension to not just be values, but an array.\n",
    "Perhaps this is for something like [R,G,B] or [H,S,V] values.  In our case the last dimension is [G] for grayscale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 784)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(42000, 28, 28, 1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xn_train.values.shape\n",
    "xn_train.values.reshape((-1,28,28,1)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can add the Conv2D layer with the correct input shape.  It will also need to be followed by a pooling layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "42000/42000 [==============================] - 7s 169us/step - loss: 0.3552 - acc: 0.8930\n",
      "Epoch 2/10\n",
      " 2100/42000 [>.............................] - ETA: 3s - loss: 0.0988 - acc: 0.9738"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AFMS\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:434: RuntimeWarning: Can save best model only with val_loss available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42000/42000 [==============================] - 4s 98us/step - loss: 0.0807 - acc: 0.9765\n",
      "Epoch 3/10\n",
      "42000/42000 [==============================] - 4s 98us/step - loss: 0.0525 - acc: 0.9840\n",
      "Epoch 4/10\n",
      "42000/42000 [==============================] - 4s 98us/step - loss: 0.0372 - acc: 0.9885\n",
      "Epoch 5/10\n",
      "42000/42000 [==============================] - 4s 98us/step - loss: 0.0291 - acc: 0.9912\n",
      "Epoch 6/10\n",
      "42000/42000 [==============================] - 4s 97us/step - loss: 0.0222 - acc: 0.9927\n",
      "Epoch 7/10\n",
      "42000/42000 [==============================] - 4s 98us/step - loss: 0.0178 - acc: 0.9946\n",
      "Epoch 8/10\n",
      "42000/42000 [==============================] - 4s 98us/step - loss: 0.0139 - acc: 0.9952\n",
      "Epoch 9/10\n",
      "42000/42000 [==============================] - 4s 98us/step - loss: 0.0130 - acc: 0.9956\n",
      "Epoch 10/10\n",
      "42000/42000 [==============================] - 4s 98us/step - loss: 0.0084 - acc: 0.9973\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1bfbb026be0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(32, (5, 5), input_shape=(28,28,1), activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(784, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "model.fit(xn_train.values.reshape(-1,28,28,1), y_train.values, batch_size=420, epochs=40, callbacks=callbacks)\n",
    "model.save('kdigit.model')\n",
    "m = tf.keras.models.load_model('kdigit.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Follow the directions to make a submission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. use the model to predict results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28000, 10)\n"
     ]
    }
   ],
   "source": [
    "y1_test = m.predict(xn_test.values.reshape(len(x_test),28,28))\n",
    "print(y1_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28000,)\n"
     ]
    }
   ],
   "source": [
    "y_test = np.argmax(y1_test, axis=1)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. submit results to kaggle and get screen shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label    int32\n",
       "dtype: object"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ImageId</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Label\n",
       "ImageId       \n",
       "1            2\n",
       "2            0"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ImageId</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27999</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28000</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Label\n",
       "ImageId       \n",
       "27999        9\n",
       "28000        2"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data=y_test.astype(int), columns=['Label'], index=pd.RangeIndex(start=1, stop=28001, step=1))\n",
    "df.index.name = \"ImageId\"\n",
    "df.dtypes\n",
    "df.head(2)\n",
    "df.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Take a screenshot or snip of your result on the leaderboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![leaderboard](./ron_leaderboard2.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ensemble with other methods\n",
    "\n",
    "### 5.1 MLP, RandomForest, SVC classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnm = MLPClassifier()\n",
    "nnm.fit(x_train,y_train)\n",
    "y_pred = nnm.predict(X_test)\n",
    "\n",
    "def print_acc(y_actual, y_pred):\n",
    "    print(\"       actual\\n       +   -\\npred+[[tp, fp]\\ndict- [fn, tn]]\")\n",
    "    print(confusion_matrix(y_actual, y_pred), \"\\n\")\n",
    "    print(\"\\n\")\n",
    "    print(classification_report(y_actual, y_pred))\n",
    "    print(accuracy_score(y_actual, y_pred))\n",
    "\n",
    "print_acc(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 ensemble with voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Follow the directions to make a submission.\n",
    "\n",
    "### 6.1. use the model to predict results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2. submit results to kaggle and get screen shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Take a screenshot or snip of your result on the leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
